[["lab-2b-research-project.html", "Lab 2B: Research Project", " Lab 2B: Research Project Last updated 2021-08-23 Over the term, you and your partner will be designing and conducting an experiment, analysing the data you generate and then presenting your results. In order to prepare you for this task, you will need to have read through the material below in advance of lab. Learning Outcomes Students will participate in the process of science and demonstrate scientific thinking. Students will be introduced to the characteristics of the experimental method of research and learn: How to form a hypothesis. How to design an experiment to test your hypothesis. How to analyse and display your results. How to interpret your results so as to support or reject your hypothesis. How to present your results as an oral presentation. In addition, you will begin to explore the principles and practices of Open Science, as a way to help ensure reproducibility and transparency in the work that you do as scientists. "],["science-the-scientific-method.html", "Science &amp; The Scientific Method", " Science &amp; The Scientific Method Science is just one of many different lenses through which we, as humans, attempt to better understand the world around us. Science as a discipline is built on the foundation of observable, measurable evidence that allows us to make testable predictions about the world. There are other ways of learning about our world (faith, intuition, memory, imagination, etc.). Each of these \"ways of knowing\" uses different kinds of evidence to help us make sense of our world. Science is also a highly collaborative endeavor, where each scientist builds on the work of their colleagues and mentors, to collectively construct scientific knowledge. This collaborative aspect is central to the ideas of Open Science, which is a key part of what you'll be learning about throughout your UBCO degree. The Scientific Method The way that we do science is that we follow a set of guidelines called \"The Scientific Method\". This method helps us make sure that we test our ideas in such a way that we've done our best to remove our own opinions and personal biases from the process. Removing personal opinions and biases, and focusing on what the evidence is telling us is absolutely vital to science. It is the heart of everything that we, as scientists, try to do every day. Deductive Logic Some scientists are interested in measuring and recording observations in nature. This is sometimes called \"descriptive science\". Scientific sampling and collection methods allow researchers to describe nature accurately. We can then use these observations to make generalizations about the world using \"deductive logic\". Inductive Logic Other scientists wonder why things are the way they are. They form ideas, or hypotheses using \"inductive logic\" about how things must work and then test these ideas in experiments that they design. Whether a scientist is conducting descriptive (observational) science or experimental science, they will be using evidence to support the claims that they make, and they will be using the framework of the scientific method to help them do this in a way that avoids bias and focuses on the evidence they have. In this term's research project we will be focusing on experimental research, rather than descriptive science. Reproducibility One of the most important concepts in science is the idea of reproducibility. This means that if our methods are carefully recorded, and shared with others, they will be able to reproduce the work that we did, and, ideally, get similar results that yield identical conclusions about the hypothesis. It also means that scientists never base their conclusions on only one experiment. We always attempt to replicate our results, by running the same experiment, following our proposed method, at least 2-3 more times (and maybe more?) to ensure that the results we are getting are consistent, and not some kind of random fluke. Shortly, we will give you information about how to build a workflow, based on Open Science practices and principles, that sets you up to best be able to replicate your results, troubleshoot what went wrong if necessary, and also to help others understand and reproduce your work. Understand that scientists do these things because they do not accept anything on faith. Because science is not a belief system; scientists are convinced only by evidence and data. Any idea is up for debate and everything can be criticized. It takes many years and many experiments to convince scientists that something is true or not true. For example, the idea that the continental plates are moving slowly over the surface of the Earth took decades to take root. It was debated and tested and tested again by many people before it was fully accepted as fact. This is as it should be… scientists don't much like to be wrong about the big stuff. We don't accept any explanation as \"true\" before every other possible explanation has been tested and rejected. It is only when we have done our best to disprove an idea, and it has stood up to everything that we've thrown at it, that we then begin to accept that maybe… just maybe… it might be true… at least for now, until new evidence is found that throws everything into doubt again. "],["open-science.html", "Open Science", " Open Science Open Science is a movement to make scientific research transparent and accessible to everyone. This not only gives the best opportunity for research to be critically examined, to ensure reproducibility, but it also makes it easier for scientists to share their work with others, and build on the work that has been done before. You will be learning more about the principles and practices of Open Science in Lab 3. For now, know that as you work on your research project, you will follow the stages of a typical registered report and implement Open Science practices including: Throughout the experiment, using appropriate version control on electronic documents and proper file and data management practices (see below). Performing a literature review on your research topic and documenting a list of consulted studies, how they were found, and the strengths, limitations, and weaknesses of each. Submitting a written proposal with an established a priori hypothesis, experimental design, and plan for presenting and analyzing your data. This will be marked before the experiment implementation phase and TA feedback incorporated into the project as needed. Creating a detailed, thorough plan for your research often takes as much time as running the experiment and collecting and analyzing your data. The more you plan, including anticipating potential problems, the easier the implementation! Implementing the study according to your plan, and noting any deviations from that plan (Note: deviations often happen, and that's OK! The key is to document them). These reflections will be submitted for marks. Submitting and presenting a poster that details your experiences implementing the research plan (including any changes recorded, justification for changes, analysis of the data, and your interpretation and conclusion). Conducting a peer review of other students' poster presentations using the poster presentation rubric as a guideline. "],["experimental-research.html", "Experimental Research", " Experimental Research Now that we've briefly introduced you to Open Science, and what it means in the context of this project, let's talk more about what you're going to be doing. In a nutshell, you are going to use the scientific method to learn something about an organism, in the controlled setting of a lab experiment. We expect that you have been exposed to the principles of the Scientific Method before this, while you were still in high school. As such, we are assuming that you have a little bit of prior knowledge to draw from. The diagram below shows the steps in a nutshell. Figure 4. Visual representation of the steps of the Scientific Method.Image by Efbrazil, licensed under CC BY 4.0 In the following sections, we will discuss each step of the scientific method, and how it applies in the context of this research project. "],["research-question.html", "0.1 Research Question", " 0.1 Research Question The first step in any research is to decide on a problem or focus for the investigation. This often happens naturally when you observe something that interests you, but that you can't entirely explain. In your head, a question forms, such as \"why did it do that?\" Deciding on a problem to explore and formulating a question is your very first task. As all good scientists, the question you ask should be informed by existing knowledge and relevant research. A review of the published scientific literature is a good way to do this. For this research project you will be using mealworms to conduct your study. Your research question must include the effect of \"x\" on some physiological parameter such as survival, some aspect of behaviour, some aspect of vision or colour vision, or some aspect of hearing. Your TA will be available to help you consider your options as you work on this. "],["statement-of-hypothesis.html", "0.2 Statement of Hypothesis", " 0.2 Statement of Hypothesis A hypothesis is an unproven explanation for the observed phenomena. In its simplest form, a hypothesis is an \"educated guess\" or intuitive hunch that is proposed as a possible answer to the question you're interested in answering. There's a couple of things to know about hypothesis building before you get started: A hypothesis is not a question, it is a statement For example, \"over a given time period, plants will grow taller at higher temperatures\" is a hypothesis, whereas \"over a given time period, will plants grow taller at a higher temperature?\" is a question. They're generally related, but they're not the same. A hypothesis must be testable The hypothesis does not need to be \"correct\" (after all, there's really no way to know that at this point) but you do have to be able to test whether it is correct or not. In our example from above, we can test the hypothesis by growing the plants at different temperatures, and measuring their heights after a set amount of time. Thus, we have a way to measure the effect of interest and test our hypothesis. A hypothesis comes before the experiment, not the other way around We call this an a priori hypothesis, meaning that we made the hypothesis before we ran the experiment and learned the answer. Sometimes, because we want to show that we knew what we were doing, we feel the need to change the hypothesis we started with, so that it better reflects the results we got. This is known as HARKing (Hypothesizing After Results are Known), and is not considered to be good science. It's important to present your hypothesis as you originally developed it, and then discuss what you have learned about the topic based on your testing of that hypothesis. "],["experimental-design.html", "0.3 Experimental Design", " 0.3 Experimental Design In this section Designing Your Experiment Planning Ahead Types of Data Types of Experiments Note: BIOL202 is the course designed to teach you the foundations of biological statistics, including experimental design, how to decide what statistical test to use when, and how to visualize data. Here we are giving you only enough information so that you will be able to complete your BIOL116 research project. We recommend that you take BIOL202 as early in your degree as possible, as it will make all of your lab work easier. Designing Your Experiment Once you have a research question and a clear and testable a priori hypothesis, you can design an experiment to test it. Variables Ideally, experiments should be conducted in such a way that the experimenter has control over every variable that might have an influence on your results (in reality this is much harder than it sounds!). A variable is any factor that might affect the outcome of the experiment. The experimenter therefore manipulates the independent variable and observes the effects of this manipulation on the dependent (or response) variable. For example, if the goal is to determine the effects of temperature on plant height after 14 days, then height is the dependent variable because it \"depends\" on the temperature to which the plant is exposed. All other variables must be controlled or held constant, to the extent possible. Temperature is the independent variable because that is the variable which is manipulated by the experimenter. The ideal way to perform such an experiment is to arrange a set of tests that are identical in all ways (light, soil moisture, etc.) except for the one specific factor that is being tested (in this case, temperature). Thus, for our plant experiment, a greenhouse with multiple temperature-control chambers would be ideal; each chamber would host a different temperature \"treatment group\". It's worth noting here that we don't always have the option to do what's ideal, but that doesn't mean we shouldn't work to control as much as possible. We should also consider carefully how the things we didn't or couldn't control might be affecting the results of our experiment. Control Crucially, one of the treatment groups must serve as a control group against which all other treatment groups are compared. The importance of the control group cannot be over emphasized. It is essential to know how the system you are investigating works under normal circumstances (i.e., before you started messing with it), before you can be sure the results obtained from the experimentation are actually due to the manipulation of the independent variable(s). To continue our example above, if you wanted to investigate the effects of temperature (the independent variable) on the height of plants after 14 days (the dependent variable), you would measure the heights of plants grown at their normal, expected temperature (most likely room temperature) as the control group, and then compare the data collected from this group to the heights of plants exposed to higher and / or lower temperatures, depending on what you're hoping to learn. The control group would provide the \"normal standard\" against which the other treatment groups would be compared. Sample Size Another important rule governing experimentation is that each treatment group (which includes the control group) should include a decent number of individual test subjects or \"replicates\" (and ideally an equal number of individuals in each group). The more replicates you include in your experiment, or in other words the larger your \"sample size\" (indicated by the letter n) per treatment group, the more confident you would be in your results and the more power your study has. However, in most situations, increasing the number of replicates increases the cost and / or logistical difficulty of the experiment. The key is to have a sufficient number of replicates per group to ensure your experiment has the power to detect meaningful treatment effects (if they exist). Determining what the minimum sample size per group should be is beyond our scope here, but for our purposes you can follow the rule of thumb that once is luck, twice is coincidence, three times is science (and five or more times is good science). Variation &amp; Random Assignment Biological variation is the inherent differences among organisms in a study that arise due to differences in genetic makeup, age, sex, health, etc. This natural variation has the potential to obscure or confuse experimental treatment effects. Thus, it is important to attempt to minimize this variation when designing your experiment (e.g., by using organisms of the same age, sex, etc.). Even when potential sources of variation are accounted for, it is crucial that subjects be randomly assigned to the treatment groups, so that any inherent variation among individuals will be distributed at random among all treatments, including the control group. Planning Ahead Raw Data The data you collect from the experiment are generally called the raw data. You should always make sure that you have a copy of these raw data stored somewhere safe, so that you or someone else could start the data analysis from scratch should the need arise (like, say, if your files got corrupted or deleted by accident). Saving a safe copy could be as simple as taking a picture of your recorded data in your lab notes with your phone, or keeping a copy of a file on both your computer and a usb stick. How do you plan to save a copy of your raw data? Checking for Errors The next step is to plan how to check for any mistakes that might have been made when recording your observations, and how to deal with them. For instance, if one of your data points is an order of magnitude larger than all others (e.g. a \"100\" instead of a \"10\"), this is likely a typo. If so, then simply state this and make the correction. But sometimes you'll see an observation that appears unusual compared to the other data points, and it's not a mistake. These are sometimes considered \"outliers\", and you need a plan in place to deal with these outliers. For instance, an honest and transparent approach is to conduct any analyses you do both with and without the outliers included, presenting both sets of results. If the exclusion of the outlier(s) doesn't change your conclusions, then great! But if it does, then you'll need to discuss this. The key is to have a clear plan in place, and to document what you did, and be honest and transparent about it! Typos and outliers are often best revealed using graphs; they'll show up as observations that are far from the other observations in your graph. Thus, visualizing your raw data with effective graphs should be the next step in your plan. Visualizing &amp; Describing Your experimental design determines what type of data you will collect, which then determines the appropriate method for describing, visualizing and analyzing the data. For your experiment, the data you collect will depend on the question you're exploring, and the hypothesis that you're testing. As such, the way that you will need to analyze and present the data will likely be different than your classmates', since their hypotheses will be different from yours. Types of Data In our example experiment, our response (dependent) variable \"plant height after 14 days\" is a continuous quantitative variable. Additional examples of continuous quantitative variables are temperature, weight, time, or distance. If instead (or in addition) we had decided to measure the number of leaves on each plant after 14 days, then this would be a discrete quantitative variable, as it can only take on discrete values. Another example of a discrete quantitative variable would be \"number of hairs on the thorax\" of a fly, or number of petals on a flower. Perhaps the species of plant we opted to use in our experiment can produce different colours of flower on different plants. If this is something we planned to measure, then the \"flower colour\" (red, pink, white) produced by each plant would be an example of a nominal categorical variable. Another example of a nominal categorical variable would be \"birth country\", or \"hair colour\". Lastly, if we had planned to judge the \"odour strength\" of the flowers, we might have scored odours as \"weak\", \"moderate\", and \"strong\", which constitutes an ordinal categorical variable, because the categories have a logical order to them. But what about our independent variable? In our example experiment, temperature is the independent variable, and let's say we subjected the plants to three different temperatures: 10, 20 (control), and 30 degrees Celsius. Strictly speaking, temperature is another example of a continuous quantitative variable. However, in our experiment we are manipulating the temperature to be exactly 10, 20, or 30 degrees Celsius. Thus, our independent variable can be considered a discrete quantitative variable, or in practice, it could also be treated as an ordinal categorical variable (either approach would be ok). In human health research, experimental studies often test the effects of different drugs on some health outcome, in which case \"drug type\" would be an example of a nominal categorical independent variable. Types of Experiments The example experiment we've been describing is a type of measured-response experiment, in which a quantitative response variable (plant height) is measured in relation to a manipulated, independent treatment variable (temperature) that, in our case, is handled as a discrete quantitative variable or ordinal categorical variable. An example of an experiment in which the response variable is a categorical variable is a choice experiment. Here, organisms such as insects or mice are presented with two or more categories of, say, food, to choose from. With categorical variables, what is measured and analyzed is the frequency of the different categories. For example, consider the a priori hypothesis that mice prefer high-protein food over low protein and high fibre foods. One could implement a single choice experiment in which 20 individual female mice (of similar age and health) were each independently provided 2 minutes within an experimental \"arena\" (the apparatus) to make a choice between the 3 food types. Across these 20 independent \"trials\", the researcher tallies the frequency with which each category of food is chosen. In this example, the dependent variable is \"food type\", and there is no independent variable. If our a priori hypothesis had been that female mice show a preference for high protein foods whereas males do not, then we could have randomly selected 20 male mice and 20 female mice to undergo the same type of choice experiment. In this case, the \"sex\" of the mouse would be the independent, nominal categorical variable, and \"food type\" would be the nominal categorical dependent variable. "],["analysis.html", "0.4 Analysis", " 0.4 Analysis In this section Descriptive Stats Statistical Tests Study Design &amp; Statistical Tests Although it is best practice to make all your data available (e.g. as a table in an appendix), it is also important to summarize and describe your data for the reader, and to present your summaries in a table. The focus here is describing and summarizing the data from the dependent variable. As with graphs, the best approach for describing data depends on the data types. Note that if you have an independent variable, and if it varied at all during the experiment despite being under your control (most instruments will vary a bit), it is important to plan to describe this also, though often this information is placed in an appendix. Since you'll be presenting your work as a poster, you should be prepared to answer questions about this, in case someone asks you. Descriptive Stats In these section we will cover the following desriptive stats: mean median mode variance standard deviation inter-quartile range proportion Scenario 1 Dependent Variable is Continuous Quantitative In this scenario you describe your dependent variable with a pair of descriptors: a measure of centre and a measure of spread. Measures of centre include the arithmetic mean (a.k.a. the average), the median, and the mode. Most of the time we use the average, and it is meant to give an idea of a \"typical\" value in your dataset. On its own, a measure of centre is not particularly useful, because one doesn't know if all data points are close to the \"typical\" (average) value, or if most of them are quite different from the average (in which case your average value isn't particularly \"typical\"!). This is why we need to describe the spread of your data too. Measures of spread include the variance (s2), the standard deviation (\"s\"), and the inter-quartile range (IQR). The IQR is described in detail at this link NEED LINK HERE, and is not discussed further here. You'll learn in BIOL202 that characteristics of your data dictate which pair of descriptors are best suited for describing your data. For now, you should know that the average should be paired with the standard deviation, and this pair is typically the preferred pair to use. The median should be paired with the IQR. The mode is less commonly used in biology. Variance \\(s{^2}\\) is a measure of how far, on average, data values deviate from the mean. A small variance indicates the data are tightly clustered around the mean. The larger the variance, the more spread out the data. Variance is calculated by summing all the squared deviations from the mean (a deviation is the difference between an individual measurement and the mean) and dividing this sum by the number of data entries minus one. \\[s^{2} =\\frac{ \\sum{(x_{i}-x)^{2}}}{n-1}\\] Standard deviation \\(s\\) is simply the square root of the variance. \\[s =\\sqrt{(\\frac{1}{n-1})\\sum_{i=1}^{n}(x_{i}-\\overline{x})^{2}}\\] Calculating and presenting your descriptive statistics PRO TIP: Most scientific calculators have a \"DATA\" mode that includes a set of functions for calculating descriptive statistics such as the average and standard deviation. But it is still important that you understand how to do calculations by hand, and what the descriptors represent. For detailed instructions on how to calculate the mean and standard deviation by hand, consult this web resource. If you're keen, you can consult these instructions on how to use the \"R\" software to do the calculations. Based on the UBCO Biology Guidelines for data presentation, measures of spread should be reported to one more decimal place than the number of decimal places that the data entries contain. If your experiment included a treatment variable that is categorical, like in our plant experiment where the three temperature treatments are handled as ordered categories (10, 20, and 30 degrees), then you should plan to calculate your descriptive statistics on the dependent variable (plant height) using the data from each of the treatment groups separately. So in our example you'd calculate the average and standard deviation of plant height for each of the three groups of height measurements, and report these in a table as described in the Procedures and Guidelines document. Scenario 2: Dependent Variable is Categorical Recall that for categorical dependent variables, like \"food type\" in our example choice experiment, we tally the frequency with which each category occurs. Imagine that the low protein food was chosen by 6 of the mice, the high fibre food was chosen 4 times, and the high protein food was chosen 10 times. These data are very straightforward to present as is in a table, but we should also calculate the main descriptive statistic for categorical data, called the \"proportion\" \\(p\\). That is simply the frequency of the particular category (say, high fibre food) divided by the total number of trials (or total sample size), here 20. Thus, for the high fibre food, the corresponding proportion \\(p = 4/20 = 0.2\\). The proportion value should always fall between 0 and 1. You should plan to report both the raw frequencies of each category alongside their corresponding proportions. If your choice experiment includes an independent categorical variable, such as sex (male / female), then you should calculate and report the raw frequencies and corresponding proportions for each category of the dependent variable (food type) for each category of the independent variable (here, male and female). Lastly, be sure to report your sample size \\(n\\) for each treatment group, regardless of what type of variable your dependent variable is. Also make sure to tally any missing values in any of the groups (e.g. that may have arisen due to problems during the experiment). Statistical Tests Now that you have decided what graph will be most appropriate for visualizing and presenting your data once they're collected, and have planned how to describe and summarize your data, it is time to make the key decision on how to best analyse your data to test your hypothesis. This decision is based on the experimental design and the type of data involved. You'll learn in BIOL202 the formal statistical tests that are most appropriate for your study. For now, we'll use less formal but generally effective approaches. First, we need to cover some foundational statistical concepts. We'll do our best to keep things simple, but the reality is that there's a lot to know to make these decisions appropriately, so at the end of the day there's a limit to how simple this can be, and still be correct. Try not to worry if it doesn't all make sense at first. Take it slow, read it more than once, work with your group, and ask lots of questions of your classmates and your TA… after all, collaboration and teamwork is what science is all about! Inferential Statistics In the previous section about planning to describe our data, we learned that the average (mean) was a useful descriptor of a \"typical value\" for a continuous, quantitative variable, and that a &lt;a href=“https://ubco-biology.github.io/Procedures-and-Guidelines/glossary#Proportion&gt;proportion was the best descriptor for categorical variables. We were planning our \"descriptive statistics\". Now our goal is to plan for drawing inferences from our data about the world at large. We are embarking on inferential statistics. We now need to cast the descriptors we calculate, like the mean, into a different light: no longer is it a simple, calculated, fixed value; now we consider it an estimate of some true mean in a population at large, and we need to recognize that this calculated value has uncertainty associated with it. For instance, for our plant experiment, we planned to describe our data, including calculating the mean plant height for each of the three treatment groups. But when it comes time to analyse our experiment data, we switch modes and consider each of those means as estimates of their respective, true population means, specific to each treatment group. But wait, we don't have populations in our experiment! We certainly don't, and experiments never do. However, so long as we randomly assigned our plants to our treatment groups, then we can safely assume that the average response we observe among the individuals in a given treatment group is representative of what we would observe if we were to subject a different random sample of plants from the same population to the exact same experimental conditions. We need to remember, however, that individuals within every population vary in many ways, and therefore if someone else were to conduct the experiment using the exact same conditions, but a new set of randomly chosen subjects (plants), randomly assigned to each treatment group, they will most certainly not get the exact same calculated values for the treatment means. This reflects something called \"sampling error\", and sampling error is entirely expected! This sampling error is what introduces uncertainty to our estimates. We must recognize that, even though we might have imposed strongly different treatments in an experiment, we can't simply interpret differences between treatment means at face value; we need to take account of the possibility that those differences could have arisen solely due to sampling error. Null and Alternative Hypotheses As scientists, we should approach new ideas and hypotheses with skepticism (even if we're actually excited about them!). We therefore undertake studies like our plant experiment with the working assumption that our research hypothesis is wrong, and we need to be convinced otherwise with good evidence. We recognize that sampling error is ever present, and that it could easily cause us to draw incorrect conclusions about our data. To formally account for the potential influence of sampling error, and help guard against drawing incorrect conclusions about our study results, we need to formulate two statistical versions of our a priori research hypothesis: a null hypothesis (H0) and an alternative hypothesis (HA). These provide clear and testable statements about what study outcomes would look like if the hypothesis was NOT supported (H0), and what would be observed if the hypothesis was supported (HA). In other words, the null hypothesis is what we expect to observe if only sampling error were at play. The alternative hypothesis is what we expect to see if there was a biological effect at play that was strong enough to overcome the influences of sampling error. Continuing with our plant experiment example, and recognizing that for this study design the suitable analysis is to compare average values of the dependent variable across treatment groups (see next section), we could write our null and alternative hypotheses as follows: H0: The average height of plants grown under different temperatures does not differ after 14 days HA: The average height of plants grown under different temperatures does differ after 14 days Correspondingly, the null hypothesis represents the status quo, i.e. nothing going on, and it is this hypothesis that we objectively and directly test through experimentation and statistical analyses; only if the evidence is strong enough to reject the null hypothesis would we conclude that the data are consistent with the alternative hypothesis, which itself reflects what we expect to see if our research hypothesis were correct. It is important to emphasize that a failure to reject the null hypothesis does not mean that the null hypothesis is true; it simply means that there is insufficient evidence to reject it at this stage. Likewise, evidence consistent with the alternative hypothesis is just that: evidence that is consistent with there being an effect of temperature on plant height. Only after sufficient and independent replication of the experiment should we conclude that our research hypothesis is true. After all, there are many factors that influence how robust your experiment is, and how likely it is to reflect the \"truth\". We call this the power of your study. Your methods, sample size, and the number of times you repeat the experiment and draw the same conclusion all play into the power of the work that you do, and how likely your results represent the underlying laws of nature. Significance &amp; Confidence The null and alternative hypotheses are typically formulated at the same time you decide which test is best suited for your study (see the next section). Also, at the same time you need to decide a clear criterion upon which to base your decision about whether the evidence is strong enough to reject the null hypothesis in favour of the alternative. This decision should be guided by a number of factors, but for the present purposes we'll go with the traditional approach, which is to guard strongly against making a mistake of a \"false positive\", i.e. rejecting the null hypothesis when in fact nothing was going on (it should not be rejected). Specifically, we set what's called a \"significance level\" (denoted with the Greek letter alpha) at 0.05, or 5%. This means that we're willing to make that \"false positive\" mistake at most 5% of the time, on average. In practice, this means that the evidence needs to be pretty strong to reject the null hypothesis. The corollary of the 5% significance level is something called the \"level of confidence\". That is, using a 5% significance level is the same as having a 95% level of confidence in something. We'll see how the significance level and level of confidence are used below. You might reasonably ask: \"Hold on a minute: how come we use such an arbitrary and hard criterion for deciding when something becomes \"statistically significant\" (i.e. evidence strong enough to reject the null hypothesis)?\" That's a fantastic question! It turns out that the practice of statistics is slowly moving away from this overly rigid approach. That, however, is an idea to be explored later in your degree (possibly in BIOL202?). For now, however, we'll stick with tradition. Study Design &amp; Statistical Tests In these section we will cover the following inferential statistical tests Confidence interval Chi squared (\\(\\chi{^2}\\)) goodness-of-fit Chi squared (\\(\\chi{^2}\\)) contingency test Comparing Means Among Treatment Groups Scenario 1: Continuous Quantitative Dependent Variable and Categorical Independent Variable This scenario is typical of measured response experiments like our plant experiment. In this scenario the typical approach is to compare the average value (the mean) of your dependent variable among the treatment groups. Our approach aims to determine whether any of the treatment groups' means differ \"significantly\" from any of the other group means. At first glance, that seems straightforward: If the mean height of plants subjected to 30 degrees was 22.2cm, and the mean height of plants subjected to 20 degrees was 18.2cm, then clearly the warmer temperature treatment yielded a significantly greater average height, right? We must remember: we're now conducting inferential statistics, so each of the treatment group means has uncertainty associated with it owing to sampling error, and that uncertainty should cause us some pause. We need to be convinced, with some level of confidence, that the difference we observe between the group means could not simply have arisen due to sampling error, but rather was most likely due to our experimental treatments. We start by writing down our statistical null and alternative hypotheses: H0: The average height of plants grown under different temperatures does not differ after 14 days HA: The average height of plants grown under different temperatures does differ after 14 days Next, as instructed in the previous section, we need to decide what \"significance level\" we wish to use. You'll learn in BIOL202 that there are many factors that influence this decision. For now, we'll follow the standard and use a 5% significance level. In short, this means that we're willing to make a false positive mistake in our conclusion at most about 5% of the time, on average. Next, we plan to calculate something called the 95% Confidence interval for the Mean for our response (dependent) variable, and we do this for each of our treatment groups separately. What purpose does the 95% Confidence interval for the Mean have? Put simply, it provides a range of values within which we are 95% confident the true population mean lies. It is a way of expressing the uncertainty in our estimate, and reflects the existence of sampling error. The specific decision to use a 95% level of confidence corresponds to the 5% level of significance, as we learned previously. To calculate the 95% confidence interval for the mean, we need the standard deviation and the sample size (n), both of which we learned about previously. \\[CI=\\overline{y}\\pm 1.96 \\frac{s}{\\sqrt{n}}\\] Where \\(\\overline{y}\\) is the mean, \\(s\\) is the standard deviation and \\(n\\) is the sample size. The value of \\(1.96\\) in the equation represents what's known as the Z-value, or Z-score. It's a little bit beyond the scope of this course to go into it, but it reflects the 95% level of confidence (or 5% significance level) that was decided upon in advance (if we decided to use a different level of confidence then the 1.96 would be changed to a something else). Once we have calculated each of the treatment group means and their respective 95% confidence intervals, we can use these to make a reasonable judgment about which, if any, group means differ significantly (with 95% confidence) from any others. Specifically, if the 95% confidence intervals of any treatment group means do not overlap, we can conclude, with 95% confidence, that they are significantly different, and that the difference reflects something other than sampling error. Therefore, we can reject the null hypothesis in favour of our alternative hypothesis, and conclude that temperature did have a significant effect on plant height after 14 days. When the 95% confidence intervals overlap, discrepancies between treatment means could have arisen solely due to sampling error. Thus, we don't reject the null hypothesis, and conclude that the data are consistent with there being no effect. Remember, this doesn't necessarily mean the null hypothesis is true! We simply don't have any evidence to suggest it's false. Comparing Frequencies to a Baseline Expectation Scenario 2: Categorical Dependent Variable Without an Independent Variable This scenario is typical of choice experiments, like the one described above with mice choosing among food types. The single categorical response variable is \"food type\". You can imagine that if there was a strong preference for one of the three food types, then that food type would be chosen more frequently by the mice than the others. Alternatively, if there was no preference, then one would expect all three food types to be selected with similar frequency. As skeptical scientists, this latter \"status quo\" scenario should be our working hypothesis, and evidence would need to be strong and clear to convince us otherwise. We need a way to quantitatively test this. For this scenario in which we have a single categorical dependent variable, we use something called a \\(\\chi{^2}\\) goodness-of-fit test (when we say it, we often call it the chi-squared test, and pronounce the greek letter, \\(\\chi\\), as Kai), which quantifies the \"fit\" of observed frequencies to those expected if nothing were going on. We now formulate suitably worded null and alternative hypotheses: H0: The three food types are chosen with equal frequency by the mice (or something similarly clear). HA: The three food types are NOT chosen with equal frequency by the mice (or something similarly clear). Although the test is relatively straightforward to undertake, you can make use of an online app to do the test. Nevertheless, below we show you what's involved, since you'll still need to interpret the results. PRO TIP: If there are only 2 categories in the dependent variable, then the most powerful statistical test to use is a binomial test, but a \\(\\chi{^2}\\) goodness-of-fit test will still work. Here is the formula to calculate the value of \\(\\chi{^2}\\) test statistic: INSERT FORMULA HERE The value of the \\(\\chi{^2}\\) test statistic increases in magnitude as the overall discrepancy between observed and expected frequencies increases. Recall that we need to consider sampling error, and the fact that sampling error will itself cause discrepancies between observed and expected frequencies. So we need to decide on a threshold value of \\(\\chi{^2}\\), called the \"critical value\", that will be large enough to convince us that something is very likely going on, and we should reject the null hypothesis in favour of the alternative. The exact value for this \"critical value\" is based in part on the significance level that we set earlier, i.e. 5%, and on the number of categories that our dependent variable has. The online app decides this for you based on your inputs. If our calculated value of \\(\\chi{^2}\\) is greater than the critical value of \\(\\chi{^2}\\), then we reject the null hypothesis in favour of the alternative, and conclude that \"Mice do show a preference for food type, as the three different food types were not chosen with equal frequency.\" Scenario 3: Categorical Dependent Variable and one Categorical Independent Variable This scenario is also typical of \"choice experiments\", and above we provided one example in which we hypothesized that female mice showed a food preference whereas males do not. In this case, we plan to conduct something called a \\(\\chi{^2}\\) contingency test, also called a \\(\\chi{^2}\\) test of association. For example, if indeed we were correct with our research hypothesis, then the evidence would show that a preference for food type is contingent on the sex of the mouse. The appropriate null and alternative hypotheses are: H0: The three food types are chosen with equal frequency by male and female mice. HA: The three food types are not chosen with equal frequency by male and female mice. An alternative but less effective wording that is common to see is: H0: There is no association between food preference and sex. HA: There is an association between food preference and sex. The latter statements are more ambiguous with respect to quantitative predictions. Nevertheless, they are acceptable. Again, we plan what significance level to use: 5%. Based on this significance level, and on the number of categories in our dependent and independent variables, we would figure out what the critical value of \\(\\chi{^2}\\) is for our test. But in our case, we'll again use an online app for the test. If our calculated value of \\(\\chi{^2}\\) is greater than the critical value of \\(\\chi{^2}\\), then we reject the null hypothesis in favour of the alternative, and conclude that \"Food preference is contingent on the sex of the mouse, because males and females chose the food types with different frequencies.\" For more details on how to report the results of statistical tests, refer to the UBCO Biology Guidelines for data presentation. "],["reporting-conclusions.html", "0.5 Reporting &amp; Conclusions", " 0.5 Reporting &amp; Conclusions In this section Graph Type &amp; Data Type Interpreting Results &amp; Conclusions Graph Type &amp; Data Type For common measured-response experimental designs, in which a continuous quantitative dependent variable is analyzed in relation to a categorical independent variable, the appropriate way to visualize the data is with a boxplot or stripchart, as described in the Procedures and Guidelines materials. INSERT EXAMPLE PLOTS For study designs in which the dependent variable is categorical, as in the food choice experiment, the appropriate way to visualize the frequency data (the tallies of the different food types chosen) is a bar graph. When there is both a dependent and independent categorical variable in the study design, then one can use a grouped bar graph or a mosaic plot to visualize the data. INSERT EXAMPLE GRAPHS Effective Graphs Regardless of the type of graph used, the independent variable (i.e., temperature in our plant example) is always placed on the horizontal (or X) axis and the dependent variable (i.e., height after 14 days) appears on the vertical (or Y) axis. For bar graphs, the y-axis will have a label \"frequency\", as that is what was measured for the categorical dependent variable. All figures must have a number (and be numbered sequentially) and a detailed title (called a \"figure heading\") that are placed below the figure. For more details consult the Biology Procedures and Guidelines document. Interpreting Results &amp; Conclusions This final step in the scientific method requires that you provide a straightforward description of the conclusions drawn from the data you collected and analysed. Do these sample means represent different populations of measurement (i.e., did you reject H0)? Or, do the sample means represent the same population of measurements (i.e. is H0 supported by this evidence)? Do the 95% confidence intervals overlap or did you find a significant Chi-squared value? Are the results from the different trials that you ran consistent with each other? How so? If your data allow you to reject H0 and provide support for HA then you need to explain the specific effect the factor had on your organism and the processes that occurred to result in this response. Does this agree with all aspects of your prediction? If not, why not? When possible, you should not only repeat your experiment as many times as is reasonable (only if planned in advance), but also compare your results to those of other investigators working on the same problem. This helps you to determine how reproducible you would expect your result to be, which also helps provide evidence for how likely your results reflect the \"truth\". It is important to remember that scientific investigations often don't yield the anticipated results. If there are discrepancies between your results and those of others, or what you expected to find based on your reading of the scientific literature, this is the place to try and explain those discrepancies. As a general rule, this means looking at the published results of other scientists, and critically comparing the work they did to yours, to see if similarities make sense, and discrepancies can be explained. All information obtained from other sources, or any ideas that are not your own, must be properly cited in the body of your poster presentation and included in a \"Literature Cited\" or \"References\" list at the end. This is an essential part of science, and academic endeavours. No scientist ever works in a vacuum, and comparing to others is expected, so it's perfectly normal and expected that you will learn from the work of others, and cite them. "],["maximizing-reproducibility.html", "Maximizing Reproducibility", " Maximizing Reproducibility Ensuring your experimental design and your plans for analysis are sound before you undertake the research is crucial. Mistakes in experimental design, or in your plans for statistical analyses, can render results entirely meaningless. To avoid such costly mistakes, and also to promote transparency, scientists often submit their experimental design and analysis plan for independent review by peers, and once the design is finalized (often after several rounds of revision), they \"register\" it so that there exists a formal record of the original design for others to view. For this project you will submit your initial experimental design and plans for analysis for feedback. "],["workflow-information-management.html", "Workflow &amp; Information Management", " Workflow &amp; Information Management As mentioned earlier, when we introduced the concept of Open Science, your group is expected to follow proper file and data management practices. Having your files and data organized appropriately will save you time. The best rule of thumb for lab experiments is to NEVER assume that you will remember exactly what you did days, weeks or months prior… you won't, and your science (as well as your lab grade) will suffer. So being organized and meticulous is absolutely vital to the success of your project. Considering how you are going to keep track of everything is one of the first decisions that you need to make as a group. If you don't write things down right from the moment you start developing your experimental plan, how will you be able to run the experiment the exact same way twice? For example, Are you going to use paper or electronic files? How will you share methods and data with each other? How are you going to keep track of the changes you make over time, in case you change your plan and need to back up to an earlier version of your experimental plan? Once you know the data you want to collect, how are you going to record it? How should that file be organized to make it as easy as possible to accurately record the data your experiment generates? How will you make sure you know which test subject/ trial each data point belongs to at all times? Once your data are recorded, how will you explore them to check for mistakes, such as typos? And how exactly will you deal with such mistakes to make the data \"clean\"? With the \"clean\" data in hand, were you able to implement the statistical analysis as originally planned? Or did you need to modify your analysis in any way? In Lab 4 (online, asynchronous lab) you will be exploring best practices for file management and naming conventions. For now, here is an example of naming a data file for an experiment investigating how mealworm movement is affected by the presence of light. 20200626_MealwormProject_Light-movement-data.csv Here is an example of naming a written proposal for the same experiment: 20200724_Mealworm-project_Proposal_V01.docx As you design your experiment, and develop (and troubleshoot!) the method you expect to use, it can be very helpful to draw out your proposed methodology into a flow chart. This can help you better visualize what you want to do, and may help you realize where you need to think a little more critically about your proposed plan and how it will work. PRO-TIP: visual representations of your methods work really well on posters! So, if you start working on it right from the start, it should be awesome by the time you're ready to build your poster! As stated earlier, all your decisions about experimental design, analyses, and data management and cleaning should be made and documented (see below) before you collect any data, otherwise you may subconsciously (or consciously) let the data influence your actions, which will bias your conclusions. Following these steps should ensure the experiment is repeatable by anyone that wishes to do so (including you!). Others will not get exactly the same results (because of sampling error), but they should have no trouble replicating the experiment - your documentation should be clear and thorough. "],["conducting-the-research.html", "Conducting the Research", " Conducting the Research At long last, you've submitted your experimental design and analysis plans for feedback, made some adjustments that were \"ok'd\", and now you can finally undertake your research! Keep lots of notes, especially with respect to any deviations from your original plans. We all know that stuff happens, so even the best laid plans can unravel. The key point is to document what you do. If your analyses were meticulously planned, including the null and alternative hypotheses, statistical tests, significance levels, critical values, etc… they should be relatively straightforward to implement once you have your data collected. Indeed, many researchers have R \"scripts\" written in advance that they tested on made-up data, such that when the real data are available, the analyses practically do themselves! "],["citing.html", "Citing", " Citing Citing the work of others Science is, at its heart, a collaborative endeavour. No scientist ever works alone, especially in the modern times we live in. As such, all scientists share ideas and information in one way or another. Information is our currency: we trade it, share it, and make it grow. This also means that giving credit to others for their ideas and information is a vitally important part of science, not to mention academic life and the Open Science movement. Again, you will learn more about Open Science and how it works next week, in the asynchronous material of Lab 3. For your written work, every time you mention an item of information or any idea that is not your own, the source must be credited in the text. This refers not only to published material but can also include personal communications from colleagues and professors. In scientific writing, we avoid using direct quotations and footnotes wherever possible. We do not copy verbatim from our sources - i.e. copy &amp; paste. Instead, put the source away when you write, so that you naturally rephrase the material into your own words. Finally, acknowledge the source using the appropriate style and format for the work you're trying to cite. While many different formats exist for citing your sources, for the purposes of this project the APA 7th edition reference and citation style is to be followed. The Procedures and Guidelines: APA Citations has a quick reference guide and other resources that you can follow up with. Academic Integrity &amp; Copyright Citing falls under two broader categories, academic integrity and copyright. Academic integrity is about honest, responsible conduct in academia. Copyright is the legal framework that governs how the things we make - the things we write and draw - can be copied and distributed by others. The Procedures and Guidelines: Academic Integrity and Copyright sections provide further guidance on each of these. "],["closing-remarks.html", "Closing Remarks…", " Closing Remarks… Time to start doing science! You will conduct your research project over the course of the term, alternating between in person sessions, when you will work with your group to plan and / or implement your research plan, and asynchronous online sessions, when you will work through Canvas modules to help you gain the skills and information you need to be successful in this project. The weekly plan is written in your course syllabus, along with which weeks are in person - called synchronous in the syllabus - and which ones are online - called asynchronous in the syllabus. Most weeks you will have something to submit that is related to this project in one way or another (except for the weeks you're actually running your experiments and collecting the data!. You will get more information about this in you first in-person lab this week. One final thought… while science is serious and noble and logical and all of the rest… it's is also exciting and fun! We can be rigorous and careful in the work we do, and also be really excited by the cool questions we're exploring. So even while you are doing your best to learn the principles of science, it is our sincere hope that you also find the joy in research and discovery! Happy Sciencing! "],["assignment.html", "Assignment", " Assignment Please use the following template for this assignment: 20210813_Lab2b_Experimental-Design-PreLab-Assignment.docx (18 KB) NOTE This assignment is due at the start of your next in-person lab (i.e. Lab 4). "]]
